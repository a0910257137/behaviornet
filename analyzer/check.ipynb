{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os \n",
    "import json \n",
    "import cv2\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_path_list = sorted(list(glob(\"/aidata/anders/objects/landmarks/ttlnmks/bboxes_*.npy\")))\n",
    "lnmk_path_list = sorted(list(glob(\"/aidata/anders/objects/landmarks/ttlnmks/lnmks_*.npy\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vim: expandtab:ts=4:sw=4\n",
    "chi2inv95 = {\n",
    "    1: 3.8415,\n",
    "    2: 5.9915,\n",
    "    3: 7.8147,\n",
    "    4: 9.4877,\n",
    "    5: 11.070,\n",
    "    6: 12.592,\n",
    "    7: 14.067,\n",
    "    8: 15.507,\n",
    "    9: 16.919\n",
    "}\n",
    "\n",
    "\n",
    "class KalmanFilter(object):\n",
    "    def __init__(self):\n",
    "        self.lnmk_dims = 10\n",
    "        ndim, dt = self.lnmk_dims, 1.\n",
    "        # Create Kalman filter model matrices.\n",
    "        self._motion_mat = np.eye(2 * ndim, 2 * ndim)\n",
    "        for i in range(ndim):\n",
    "            self._motion_mat[i, ndim + i] = dt\n",
    "        self._update_mat = np.eye(ndim, 2 * ndim)\n",
    "        self._std_weight_position = 1. / 20\n",
    "        self._std_weight_velocity = 1. / 160\n",
    "\n",
    "    def initiate(self, measurement, obj_h=735):\n",
    "\n",
    "        mean_pos = measurement\n",
    "        mean_vel = np.zeros_like(mean_pos)\n",
    "        mean = np.r_[mean_pos, mean_vel]\n",
    "        \n",
    "        std = list(2 * self._std_weight_position * measurement) + list(\n",
    "            10 * self._std_weight_velocity * measurement)\n",
    "        \n",
    "        covariance = np.diag(np.square(std))\n",
    "        return mean, covariance\n",
    "\n",
    "    def predict(self, mean, covariance, obj_h):\n",
    "        std_pos = self._std_weight_position * mean[:10]\n",
    "        std_vel = self._std_weight_velocity * mean[:10]\n",
    "        \n",
    "        motion_cov = np.diag(np.square(np.r_[std_pos, std_vel]))\n",
    "\n",
    "        mean = np.dot(self._motion_mat, mean)\n",
    "        covariance = np.linalg.multi_dot(\n",
    "            (self._motion_mat, covariance, self._motion_mat.T)) + motion_cov\n",
    "        \n",
    "        return mean, covariance\n",
    "\n",
    "    def project(self, mean, covariance):\n",
    "        std = self._std_weight_position * mean[:10]\n",
    "        innovation_cov = np.diag(np.square(std))\n",
    "        mean = np.dot(self._update_mat, mean)\n",
    "        covariance = np.linalg.multi_dot(\n",
    "            (self._update_mat, covariance, self._update_mat.T))\n",
    "        return mean, covariance + innovation_cov\n",
    "\n",
    "    def update(self, mean, covariance, measurement):\n",
    "        projected_mean, projected_cov = self.project(mean, covariance)\n",
    "        \n",
    "        chol_factor, lower = scipy.linalg.cho_factor(projected_cov,\n",
    "                                                     lower=True,\n",
    "                                                     check_finite=False)\n",
    "        kalman_gain = scipy.linalg.cho_solve((chol_factor, lower),\n",
    "                                             np.dot(covariance,\n",
    "                                                    self._update_mat.T).T,\n",
    "                                             check_finite=False).T\n",
    "        innovation = measurement - projected_mean\n",
    "        new_mean = mean + np.dot(innovation, kalman_gain.T)\n",
    "        new_covariance = covariance - np.linalg.multi_dot(\n",
    "            (kalman_gain, projected_cov, kalman_gain.T))\n",
    "        return new_mean, new_covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseEstimator:\n",
    "    \"\"\"Estimate head pose according to the facial landmarks\"\"\"\n",
    "    def __init__(self, img_size=(480, 640)):\n",
    "        self.size = img_size\n",
    "        # Camera internals\n",
    "        self.focal_length = self.size[1]\n",
    "        self.camera_center = (self.size[1] / 2, self.size[0] / 2)\n",
    "        self.camera_matrix = np.array(\n",
    "            [[self.focal_length, 0, self.camera_center[0]],\n",
    "             [0, self.focal_length, self.camera_center[1]], [0, 0, 1]],\n",
    "            dtype=\"double\")\n",
    "        # Assuming no lens distortion\n",
    "        self.dist_coeefs = np.zeros((4, 1))\n",
    "        # Rotation vector and translation vector\n",
    "        self.r_vec = np.array([[0.01891013], [0.08560084], [-3.14392813]])\n",
    "\n",
    "        self.t_vec = np.array([[-14.97821226], [-10.62040383],\n",
    "                               [-2053.03596872]])\n",
    "\n",
    "        \"\"\"\n",
    "         if os.path.isfile('/home/anders/projects/lite_model/behaviornet/assets/calibration.yml'):\n",
    "            mtx, dist, rvecs, tvecs = self.load_coefficients(\n",
    "                '/home/anders/projects/lite_model/behaviornet/assets/calibration.yml')\n",
    "            self.camera_matrix = mtx\n",
    "            self.dist_coeefs = dist\n",
    "        \"\"\"\n",
    "        #     self.r_vec = rvecs\n",
    "        #     self.t_vec = tvecs\n",
    "        # 3D model points.\n",
    "        self.model_points_68 = self._get_full_model_points()\n",
    "\n",
    "    def load_coefficients(self, path):\n",
    "        '''Loads camera matrix and distortion coefficients.'''\n",
    "        # FILE_STORAGE_READ\n",
    "        cv_file = cv2.FileStorage(path, cv2.FILE_STORAGE_READ)\n",
    "        # note we also have to specify the type to retrieve other wise we only get a\n",
    "        # FileNode object back instead of a matrix\n",
    "        camera_matrix = cv_file.getNode('K').mat()\n",
    "        dist_matrix = cv_file.getNode('D').mat()\n",
    "        rvecs = cv_file.getNode('R').mat()\n",
    "        tvecs = cv_file.getNode('T').mat()\n",
    "        cv_file.release()\n",
    "        return [camera_matrix, dist_matrix, rvecs, tvecs]\n",
    "\n",
    "    def _get_full_model_points(self, filename='/home/anders/projects/lite_model/behaviornet/assets/model.txt'):\n",
    "        \"\"\"Get all 68 3D model points from file\"\"\"\n",
    "        raw_value = []\n",
    "        with open(filename) as file:\n",
    "            for line in file:\n",
    "                raw_value.append(line)\n",
    "        model_points = np.array(raw_value, dtype=np.float32)\n",
    "        model_points = np.reshape(model_points, (3, -1)).T\n",
    "        # Transform the model into a front view.\n",
    "        model_points[:, 2] *= -1\n",
    "        # fetch lnmk25\n",
    "        lnmks_68 = [\n",
    "            0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
    "            19, 20, 21, 22, 23, 24, 25, 26, 36, 37, 38, 39, 40, 41, 42, 43, 44,\n",
    "            45, 46, 47, 27, 28, 29, 30, 31, 32, 33, 34, 35, 48, 49, 50, 51, 52,\n",
    "            53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67\n",
    "        ]\n",
    "        # correct to our facial landmarks\n",
    "        model_points = model_points[lnmks_68]\n",
    "        lnmk_scheme = [\n",
    "            27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 48, 50, 51,\n",
    "            52, 54, 56, 57, 58\n",
    "        ]\n",
    "        model_points = model_points[lnmk_scheme]\n",
    "        LE = np.mean(model_points[:6], axis=0, keepdims=True)\n",
    "        RE = np.mean(model_points[6:12], axis=0, keepdims=True)\n",
    "        N = model_points[13:14]  #13\n",
    "        LM = model_points[14:15]\n",
    "        RM = model_points[18:19]\n",
    "        model_points = np.concatenate([LE, RE, N, LM, RM], axis=0)\n",
    "\n",
    "        #----------------------------\n",
    "\n",
    "        model_points = np.asarray(model_points)\n",
    "        return model_points\n",
    "\n",
    "    def solve_pose_by_68_points(self, image_points):\n",
    "        \"\"\"\n",
    "        Solve pose from all the 68 image points\n",
    "        Return (rotation_vector, translation_vector) as pose.\n",
    "        \"\"\"\n",
    "        if self.r_vec is None:\n",
    "            (_, rotation_vector, translation_vector) = cv2.solvePnP(\n",
    "                self.model_points_68, image_points, self.camera_matrix,\n",
    "                self.dist_coeefs)\n",
    "            self.r_vec = rotation_vector\n",
    "            self.t_vec = translation_vector\n",
    "        print(image_points)\n",
    "        (_, rotation_vector,\n",
    "         translation_vector) = cv2.solvePnP(self.model_points_68,\n",
    "                                            image_points,\n",
    "                                            self.camera_matrix,\n",
    "                                            self.dist_coeefs,\n",
    "                                            rvec=self.r_vec,\n",
    "                                            tvec=self.t_vec,\n",
    "                                            useExtrinsicGuess=True,\n",
    "                                            flags = cv2.SOLVEPNP_ITERATIVE)\n",
    "        return (rotation_vector, translation_vector)\n",
    "width, height = 1280, 720\n",
    "pose_estimator = PoseEstimator(img_size=(height, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[724.8267  307.9425 ]\n",
      " [873.3116  322.55658]\n",
      " [808.      382.5    ]\n",
      " [738.9631  453.55182]\n",
      " [845.8246  461.49222]]\n",
      "-1.840414782531409 -0.1472769949432815 -4.0862451110157565\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xxx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-17b56f23bec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mroll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m180\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mroll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpitch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myaw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mxxx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xxx' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "kf_lnmk = KalmanFilter()\n",
    "temp_lnmk = None\n",
    "mean_lnmk = None\n",
    "for i, (box_path, lnmk_path) in enumerate(zip(box_path_list, lnmk_path_list)):\n",
    "    if (i==2):\n",
    "\n",
    "        bboxes= np.load(box_path)\n",
    "        bboxes = bboxes.reshape([15, 6])\n",
    "        valid_mask = np.all(np.isfinite(bboxes), axis=-1)\n",
    "        bboxes = bboxes[valid_mask]\n",
    "        lnmks= np.load(lnmk_path)\n",
    "        lnmks = lnmks.reshape([-1, 11])\n",
    "        hws = bboxes[:, 2:4] - bboxes[:, :2]\n",
    "        areas = hws[:, 0] * hws[:, 1]\n",
    "        if len(areas) != 0:\n",
    "            idx = np.argmax(areas, axis=0)\n",
    "            bbox = bboxes[idx]\n",
    "            tl, br = bbox[:2], bbox[2:4]\n",
    "            y1, x1 = tl\n",
    "            y2, x2 = br\n",
    "            lnmk_scs = lnmks[:, -1]\n",
    "            max_idx = np.argmax(lnmk_scs)\n",
    "            lnmk = lnmks[max_idx, :-1].reshape([5, 2])\n",
    "            logical_y = np.logical_and(y1 < lnmk[:, :1],\n",
    "                                       lnmk[:, :1] < y2)\n",
    "            logical_x = np.logical_and(x1 < lnmk[:, 1:],\n",
    "                                       lnmk[:, 1:] < x2)\n",
    "            logical_yx = np.concatenate([logical_y, logical_x], axis=-1)\n",
    "            inside_masks = np.all(logical_yx, axis=-1)\n",
    "            lnmk = lnmk[inside_masks]\n",
    "            temp_lnmk = lnmk.reshape([-1])\n",
    "            if mean_lnmk is None:\n",
    "                mean_lnmk, covariance_lnmk = kf_lnmk.initiate(temp_lnmk, (y2 - y1))\n",
    "                lnmks = mean_lnmk[:10]\n",
    "            elif(i ==1):\n",
    "                mean_lnmk, covariance_lnmk = kf_lnmk.predict(\n",
    "                                        mean_lnmk, covariance_lnmk, (y2 - y1))\n",
    "\n",
    "                mean_lnmk, covariance_lnmk = kf_lnmk.update(\n",
    "                                        mean_lnmk, covariance_lnmk, temp_lnmk)\n",
    "                lnmks = mean_lnmk[:10]\n",
    "            elif(i ==2):\n",
    "\n",
    "                mean_lnmk, covariance_lnmk = kf_lnmk.predict(\n",
    "                                        mean_lnmk, covariance_lnmk, (y2 - y1))\n",
    "\n",
    "                mean_lnmk, covariance_lnmk = kf_lnmk.update(\n",
    "                                        mean_lnmk, covariance_lnmk, temp_lnmk)\n",
    "\n",
    "                lnmks = mean_lnmk[:10]\n",
    "            lnmks = lnmks.reshape([5, 2])\n",
    "            marks=  lnmks[..., ::-1]\n",
    "            pose = pose_estimator.solve_pose_by_68_points(marks)\n",
    "\n",
    "            r_mat, _ = cv2.Rodrigues(pose[0])\n",
    "            p_mat = np.hstack((r_mat, np.array([[0], [0], [0]])))\n",
    "            _, _, _, _, _, _, u_angle = cv2.decomposeProjectionMatrix(p_mat)\n",
    "            pitch, yaw, roll = u_angle.flatten()\n",
    "            if roll > 0:\n",
    "                    roll = 180 - roll\n",
    "            elif roll < 0:\n",
    "                roll = -(180 + roll)\n",
    "            print(pitch, yaw, roll)\n",
    "            xxx\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
